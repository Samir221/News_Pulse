{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731051db",
   "metadata": {},
   "source": [
    "## Find the Relations of the Articles to Micro-Sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c800d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import openai\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "\n",
    "# Agent imports\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "# Tool imports\n",
    "from langchain.agents import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.utilities import TextRequestsWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "451337e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use find_dotenv to locate the file\n",
    "dotenv_path = find_dotenv()\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Fetch the specific keys\n",
    "apikey_openai = os.getenv('apikey_openai')\n",
    "GOOGLE_CSE_ID = os.getenv('apikey_GOOGLE_CSE_ID')\n",
    "GOOGLE_API_KEY = os.getenv('apikey_GOOGLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e625ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prompt_length = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b250fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client.from_service_account_json(r'C:\\Users\\samir\\OneDrive\\Desktop\\News Stock Relevance Project\\service path\\newspulse-1b847-92ee0b8c89f0.json')\n",
    "\n",
    "# Construct a reference to the \"dataset_id\" dataset\n",
    "dataset_ref = client.dataset(\"stocklist\")  # replace \"dataset_id\" with your dataset ID\n",
    "\n",
    "# Construct a reference to the \"table_id\" table\n",
    "table_ref = dataset_ref.table(\"us-stocklist\")  # replace \"table_id\" with your table ID\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Load table data to a DataFrame\n",
    "df = client.list_rows(table).to_dataframe()\n",
    "\n",
    "# Assuming you have a DataFrame called 'df' and a column named 'Micro-sectors'\n",
    "microsectors = df['MicroSectors'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aff0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract micro-sectors from merged dataframe\n",
    "micro_sectors = df['MicroSectors'].tolist()\n",
    "\n",
    "# Remove duplicate micro-sectors\n",
    "unique_micro_sectors = list(set([sector.strip() for sectors in micro_sectors for sector in sectors.split(',')]))\n",
    "\n",
    "# DELETE IN PRODUCTION\n",
    "#micro_sectors = random.choice(unique_micro_sectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4eb8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Articles\n",
    "articles_df = pd.read_csv(r\"C:\\Users\\samir\\OneDrive\\Desktop\\News Stock Relevance Project\\articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name='gpt-4-32k',temperature=0, openai_api_key=apikey_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GoogleSearchAPIWrapper(google_api_key=GOOGLE_API_KEY, google_cse_id=GOOGLE_CSE_ID)\n",
    "\n",
    "requests = TextRequestsWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce1b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "Comedian Sarah Silverman and two authors have filed copyright infringement lawsuits against Meta Platforms and OpenAI for allegedly using their content without permission to train artificial intelligence language models.\n",
    "\n",
    "The proposed class action lawsuits filed by Silverman, Richard Kadrey and Christopher Golden in San Francisco federal court Friday allege Facebook parent company Meta and ChatGPT maker OpenAI used copyrighted material to train chat bots.\n",
    "\n",
    "Meta and OpenAI, a private company backed by Microsoft, did not immediately respond to requests for comment on Sunday.\n",
    "\n",
    "The lawsuits underscore the legal risks developers of chat bots face when using troves of copyrighted material to create apps that deliver realistic responses to user prompts.\n",
    "\n",
    "Silverman, Kadrey and Golden allege Meta and OpenAI used their books without authorization to develop their so-called large language models, which their makers pitch as powerful tools for automating tasks by replicating human conversation.\n",
    "\n",
    "\n",
    "NYC law requires companies to prove A.I. hiring software is not racist or sexist\n",
    "JULY 6, 202302:08\n",
    "In their lawsuit against Meta, the plaintiffs allege that leaked information about the companyâ€™s artificial intelligence business shows their work was used without permission.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363dc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "\n",
    "input_template = \"\"\"\n",
    "Act as a news analyst/financial analyst/economist, and please analyze ONLY WHICH OF THESE business sector(s): {unique_micro_sectors}\n",
    "\n",
    "would be directly impacted from the information in this news article: {article}.\n",
    "\n",
    "\n",
    "PLEASE THOROUGHLY EXAMINE THE ENTIRE LIST ABOVE OF BUSINESS SECTORS AGAINST THE CONTENTS OF THE ARTICLE.\n",
    "There may be more than one business sector impacted so please include ALL DIRECTLY impacted business sector(s) from the list.\n",
    "\n",
    "PLEASE Just return a PYTHON LIST of IMPACTED BUSINESS SECTORS, do not add ANYTHING ELSE, NO INTERPRETATION AND IF NO \n",
    "BUSINESS SECTOR(S) ARE IMPACTED JUST RETURN THE WORD 'NONE'.\n",
    "\n",
    "Your response should be a list of comma separated values, eg: `foo, bar, baz` or \"NONE\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "magnitude_template = \"\"\"\n",
    "Now please assign a magnitude score for each impacted business sector above as low/medium/high. \n",
    "\n",
    "PLEASE RETURN THE IMPACTED BUSINESS SECTOR(S) ALONG WITH THEIR MAGNITUDE SCORE IN A DICTIONARY.\n",
    "\n",
    "Your response should be a python dictionary separated values, eg: `[\"AI\" : \"low\", \"Banking\" : \"High\"]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "company_specific_template = \"\"\"\n",
    "Please answer 'Yes' if this article's content names any specific companies or 'No' if not.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "llm = OpenAI(temperature=0, model_name='gpt-3.5-turbo',openai_api_key=apikey_openai)\n",
    "\n",
    "sector_analysis = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory(),\n",
    ")\n",
    "\n",
    "ListofImpactedSectors = sector_analysis.run({\"input\": input_template.format(article=article, unique_micro_sectors=unique_micro_sectors)})\n",
    "\n",
    "magnitude_dict = sector_analysis.run(magnitude_template)\n",
    "\n",
    "specific_company = sector_analysis.run(company_specific_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf00705",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_analysis.run(\"Why is social networking not directly impacted by this news?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f8e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee4f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ListofImpactedSectors = list(ListofImpactedSectors.split(\", \"))\n",
    "magnitude_dict = eval(magnitude_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ef33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ListofImpactedSectors)\n",
    "print(magnitude_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from language.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "memory = ConversationBuggerMemory(memory_key='chat_history', return_messages=True, output_keys='answer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bcd683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from language.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "memory = ConversationBuggerMemory(memory_key='chat_history', return_messages=True, output_keys='answer')\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=apikey_openai)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory(),\n",
    "    article=article,\n",
    "    unique_micro_sectors=unique_micro_sectors\n",
    ")\n",
    "\n",
    "out1 = conversation.run(prompt_template, article=article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e30bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=apikey_openai)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=5000, chunk_overlap=350)\n",
    "docs = text_splitter.create_documents([article])\n",
    "\n",
    "# Get your chain ready to use\n",
    "chain = load_summarize_chain(llm=llm, chain_type='map_reduce', verbose=True)\n",
    "\n",
    "output = chain.run(docs)\n",
    "\n",
    "# Pass the summarized text to another prompt\n",
    "article = output\n",
    "prompt = prompt_template\n",
    "response = langchain.ask(prompt, context=summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b79314",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a858422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "\n",
    "# Summarize the article\n",
    "chain = langchain.refine()\n",
    "summary = chain(article, prompt=\"Summarize this article.\")\n",
    "\n",
    "# Extract the summary from the context\n",
    "summary = langchain.extract_summary(summary)\n",
    "\n",
    "# Pass the summarized text to another prompt\n",
    "prompt = prompt_template\n",
    "response = langchain.ask(prompt, context=summary)\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1310930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenAI API credentials\n",
    "openai.api_key = apikey_openai\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine='text-davinci-003',\n",
    "    prompt=\"\"\"\n",
    "        Act as a financial analyst/news analyst/economist, now please tell which of these these business sectors: {unique_micro_sectors} are impacted from the information in this news article: {article}. Please respond only with the impacted business sector(s) that have been listed here and attach a score for magnitutude (low, medium, high) for the level of impact for each impacted business sector.\n",
    "    \"\"\"[:max_prompt_length],\n",
    "    max_tokens=4097,  #Adjust as needed\n",
    "    temperature=0,  # Adjust as needed\n",
    "    n=1  # Adjust as needed\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d5ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(toolkit, llm, agent=\"zero-shot-react-description\", verbose=True, return_intermediate_steps=True)\n",
    "\n",
    "\n",
    "response = agent({\"input\": prompt_template.format(article=article, unique_micro_sectors=unique_micro_sectors)})\n",
    "response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dabf931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_list(list, value):\n",
    "  \"\"\"\n",
    "  Searches a list for the value and returns True if it exists\n",
    "  Args:\n",
    "    list: The list to search\n",
    "    value: The value to search for\n",
    "  \"\"\"\n",
    "  found = False\n",
    "\n",
    "  for i in range(len(list)):\n",
    "    if list[i] == value:\n",
    "      found = True\n",
    "      break\n",
    "\n",
    "  return found\n",
    "\n",
    "\n",
    "search_list(unique_micro_sectors, \"Discount Airlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d670e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_micro_sectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
